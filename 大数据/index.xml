<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>大数据s on Kohaku</title>
    <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/</link>
    <description>Recent content in 大数据s on Kohaku</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 26 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Flink JobManager 新版</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink-JobManager-%E6%96%B0%E7%89%88/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink-JobManager-%E6%96%B0%E7%89%88/</guid>
      <description>目录  📚理解什么是 Flink 和 JobManager：包括 Flink 的核心概念，以及 JobManager 的功能和角色。 💡深入研究 Flink JobManager 的架构：包括它的组件以及它们如何交互。 🚀通过实例来学习如何配置和使用 JobManager：包括设置参数，提交作业，以及监控作业的状态。 💡学习 Flink JobManager 的故障恢复策略：了解如何处理 JobManager 的故障，以及如何优化其性能。 🚀动手实践：配置一个具有高可用性的 Flink JobManager，并对其进行性能优化。  概念 Flink 是一款开源的流处理框架，由 Apache Software Foundation 托管。📚它的核心设计思想是“批处理是流处理的一种特殊情况”，因此它提供了统一的流处理和批处理解决方案。</description>
    </item>
    
    <item>
      <title>转行数据理由</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E8%BD%AC%E8%A1%8C%E6%95%B0%E6%8D%AE%E7%90%86%E7%94%B1/</link>
      <pubDate>Wed, 19 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E8%BD%AC%E8%A1%8C%E6%95%B0%E6%8D%AE%E7%90%86%E7%94%B1/</guid>
      <description>就目前就业市场来看前后端这类开发岗位基本上叫苦连天，很多人找不到工作(这是比较真实的情况)，而大数据开发类型的我在网上和有关求职 APP 上看到的抱怨较少而且开的工资普遍比开发岗位要来的多。仔细了解后更是觉得大数据这行会在 AI 蓬勃发展后跟着发展起来，未来会有越来越多的人去了解大数据去学习大数据，毕竟 AI 是绝对离不了数据的，好的 AI 更是如此。
(未完待续……)</description>
    </item>
    
    <item>
      <title>Flink 基本原理</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</guid>
      <description>Flink 是一个分布式大数据处理框架，它可以处理大量数据，并提供快速、可靠和实时的数据处理能力。Flink 的基本原理可以通过以下几个简单的概念来理解：
  数据流：Flink 使用数据流的概念来表示处理的数据。数据流是一个连续的数据元素序列，这些元素被处理、转换和输出到最终的结果中。简单说，数据流就是从数据源（如文件、数据库等）读取的数据，在 Flink 中经过一系列处理操作，最后输出到目的地（如另一个文件、数据库等）。
  节点和任务：Flink 任务是数据处理的基本单元。一个任务可以是一个简单的数据转换，例如过滤、映射等，也可以是更复杂的操作，例如聚合、排序等。任务在 Flink 中以节点的形式存在。节点是构成 Flink 数据流图的基本元素，数据流图是 Flink 对数据处理流程的一种抽象表示。
  并行处理：Flink 具有很好的并行处理能力。这意味着它可以将一个任务划分为多个子任务，在多个计算资源（如 CPU、内存等）上同时处理，以提高整体处理速度。Flink 会自动将任务划分为多个子任务，并行执行，最后将结果汇总。</description>
    </item>
    
    <item>
      <title>分布式缓存</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</guid>
      <description>分布式缓存（Distributed Cache）是一种在分布式计算环境中存储和共享数据的技术。它允许在计算集群的各个节点之间共享数据，以便更快、更高效地进行计算。以下几个关键点可以帮助理解分布式缓存的基本概念：
  数据共享：分布式缓存允许在分布式计算节点之间共享数据。这可以确保各计算节点可以访问到相同的数据，从而提高计算性能和一致性。
  缓存：分布式缓存通常将数据存储在内存中，以便在计算过程中快速访问。这有助于减少数据访问延迟，提高计算效率。
  一致性：分布式缓存需要在不同节点之间维护数据的一致性。这通常需要采用一些同步和数据复制技术，以确保各节点上的数据保持一致。
  在 Flink 中，分布式缓存处于辅助性地位，主要用于提高数据访问性能和简化数据共享。Flink 提供了一种简单的分布式缓存机制，允许用户将本地或远程文件作为缓存文件注册到 Flink 任务中。这些缓存文件会被分发到所有计算节点，并在本地文件系统中缓存。然后，在 Flink 任务的处理过程中，用户可以通过分布式缓存 API 快速访问这些缓存文件。</description>
    </item>
    
    <item>
      <title>广播变量</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F/</guid>
      <description>广播变量（Broadcast Variables）是一种特殊的数据结构，用于在分布式计算环境中共享数据。在许多大数据处理任务中，广播变量可以有效解决数据共享和同步的问题。以下几个关键点可以帮助理解广播变量的基本概念：
  全局共享：广播变量是一个全局共享的数据结构，它可以被所有计算节点访问。这意味着广播变量中的数据可以在整个计算集群中传播和共享，从而确保所有节点可以访问到相同的数据。
  只读：广播变量是只读的，这意味着一旦创建并广播，它的内容就不能再修改。这有助于保持数据的一致性，并避免在分布式环境中出现数据竞争和同步问题。
  缓存：广播变量通常会在每个计算节点上进行缓存，以便在处理过程中快速访问。这有助于减少数据传输和通信开销，提高计算性能。
  在 Flink 中，广播变量处于辅助性地位，主要用于解决数据共享和同步的问题。Flink 支持在 DataStream API 和 DataSet API 中使用广播变量。在 Flink 中使用广播变量的典型场景包括：</description>
    </item>
    
    <item>
      <title>数据处理时间</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4/</guid>
      <description>在 Flink 中，数据处理时间是一个重要概念，它与数据处理过程中的时间相关性有关。Flink 支持两种主要的时间概念：事件时间（Event Time）和处理时间（Processing Time）。这两种时间概念有各自的特点和用途，我们将分别讨论它们。
 事件时间（Event Time）： 事件时间是指数据元素产生时的时间戳。这意味着数据中的每个元素都有一个与之相关的事件时间。这个时间通常是由数据产生源（如传感器、日志记录器等）记录的。Flink 使用水位线（Watermark）机制来处理事件时间。水位线是一种特殊的数据元素，表示某一时刻之前的所有事件已经到达系统。这可以帮助 Flink 确定何时可以对基于事件时间的窗口进行计算和输出。  使用事件时间的优势在于可以保证处理的结果与数据发生的时间顺序一致，即使数据源产生了乱序或延迟数据。这对于需要准确计算基于事件发生时间的统计信息、分析和报告的应用场景非常重要，例如金融交易分析、传感器数据处理等。
处理时间（Processing Time）： 处理时间是指 Flink 接收到数据元素时的系统时间。处理时间依赖于数据元素到达 Flink 系统的顺序和速度。由于数据到达的顺序可能与实际发生的顺序不同，因此基于处理时间的计算可能会受到数据延迟和乱序的影响。  处理时间的优势在于它简化了时间处理逻辑，因为 Flink 只需考虑当前系统时间。此外，处理时间通常具有较低的延迟，因为它不需要等待水位线或其他时间同步机制。这对于需要快速响应和实时反馈的应用场景非常有用，例如实时监控和报警。</description>
    </item>
    
    <item>
      <title>状态和容错</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8A%B6%E6%80%81%E5%92%8C%E5%AE%B9%E9%94%99/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8A%B6%E6%80%81%E5%92%8C%E5%AE%B9%E9%94%99/</guid>
      <description>在 Flink 中，状态（State）和容错（Fault Tolerance）是两个关键概念，它们确保了数据处理过程的可靠性和一致性。我们将分别讨论这两个概念：
 状态（State）： 状态是 Flink 任务执行过程中的中间数据。在处理数据流时，任务可能需要根据之前处理过的数据元素来决定如何处理当前的数据元素。这些之前处理过的数据以状态的形式存储。状态可以是简单的计数器、列表，也可以是复杂的数据结构，如哈希表、窗口缓冲区等。  Flink 提供了丰富的状态类型和状态访问接口，以便用户可以根据需要选择合适的状态类型，并在任务中方便地操作状态。Flink 还支持状态后端（State Backend）的概念，用于存储和管理状态数据。状态后端可以是内存、文件系统或分布式存储系统，具体取决于性能、持久性和可扩展性等需求。
容错（Fault Tolerance）： 容错是指在面对系统故障（如节点宕机、网络故障等）时，Flink 能够保证数据处理的正确性和一致性。为了实现容错，Flink 采用了一种称为“检查点”（Checkpoint）的机制。检查点是 Flink 任务执行过程中的某个时刻的状态快照。Flink 会周期性地将任务的状态保存到检查点中，并将检查点存储到可靠的外部存储系统（如分布式文件系统）。  当发生故障时，Flink 可以从最近的检查点恢复任务执行。这意味着 Flink 会重新加载检查点中的状态数据，并从检查点对应的数据流位置开始重新处理数据。这样，Flink 可以保证在故障发生后，数据处理可以从一个已知的正确状态开始，并保证处理结果的一致性。</description>
    </item>
    
    <item>
      <title>迭代计算</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E8%BF%AD%E4%BB%A3%E8%AE%A1%E7%AE%97/</link>
      <pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E8%BF%AD%E4%BB%A3%E8%AE%A1%E7%AE%97/</guid>
      <description>迭代计算是一种反复执行计算过程，直到满足某种终止条件的计算方法。在许多数据处理任务中，迭代计算是一种常见的处理模式，尤其是在图计算、机器学习等领域。迭代计算的基本概念可以通过以下几个关键点来理解：
  初始状态：迭代计算开始时，需要一个初始状态。这个状态通常包含一些基本的数据和参数，用于启动迭代过程。
  迭代函数：迭代函数是一个用于更新状态的函数。在每次迭代中，迭代函数会根据当前状态计算新的状态。迭代函数可以是简单的数学公式，也可以是复杂的数据处理逻辑。
  终止条件：终止条件是一个用于判断迭代是否结束的条件。当终止条件满足时，迭代计算停止，输出最终结果。终止条件可以是迭代次数、误差阈值等。
  在 Flink 中，迭代计算是一个重要的处理模式。Flink 支持在数据流中执行迭代计算，这使得 Flink 可以处理那些需要反复执行计算过程的任务，例如图计算、机器学习等。Flink 提供了两种迭代计算模式：批量迭代和流式迭代。
  批量迭代（DataSet API）： Flink 的 DataSet API 支持批量迭代计算。在这种模式下，迭代计算是基于批处理数据集进行的。批量迭代在每次迭代中处理整个数据集，然后更新状态。当满足终止条件时，批量迭代结束，并输出最终结果。批量迭代适用于那些需要对整个数据集进行全局分析的任务，如图计算、聚类分析等。</description>
    </item>
    
    <item>
      <title>实时数据 Flink 路线图</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE-Flink-%E8%B7%AF%E7%BA%BF%E5%9B%BE/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE-Flink-%E8%B7%AF%E7%BA%BF%E5%9B%BE/</guid>
      <description>以下是 GPT4 生成的为期三个月的 Flink 实时数据开发的路线图，每个技能及学习的知识都列出了具体时限以及实践内容
 了解你的需求。下面是一个针对 Flink 实时数据开发（使用 Java）的学习路线图，其中每个阶段都包含实践内容：
  Java 基础加强（1 周）：
 学习 Java 面向对象编程（OOP）的概念，如类、对象、继承、封装和多态。 熟悉 Java 集合框架，如 List、Set、Map 等。 学习 Java 8 新特性，如 Lambda 表达式、Stream API 和 Optional 类。 实践：完成一些简单的 Java 编程练习，如实现数据结构和算法。    数据库与 SQL（1 周）：</description>
    </item>
    
    <item>
      <title>实时数据开发语言选型</title>
      <link>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80%E9%80%89%E5%9E%8B/</link>
      <pubDate>Mon, 17 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kohaku.ink/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80%E9%80%89%E5%9E%8B/</guid>
      <description>以下回答均由 GPT4 生成，后续会根据实际使用情况做更改
 问：做 Flink 实时流数据开发使用 Python 还是 Scala 更好？ 在实时流数据处理中，Apache Flink 提供了对 Java、Scala 和 Python 的支持。然而，在性能和生态系统方面，Scala 和 Java 通常比 Python 更优越。以下是关于在 Flink 实时流数据开发中选择 Python 和 Scala 的一些比较：</description>
    </item>
    
  </channel>
</rss>
