{"/":{"title":"Kohaku","content":"## About\n我是 Kohaku，一名软件开发工程师，这是我的个人数字花园，用来记录平时的闪念笔记以及总结内容。\n\n## Content\n### 大数据学习\n[[大数据/转行数据理由]]\n\n[[大数据/实时数据 Flink 路线图]]\n\n[[大数据/Flink 基本原理]]\n\n### 兴趣爱好\n[[漫画/Anime 花园]]\n\n[[动画/动画]]\n\n### 年度计划\n[[年度计划]]\n\n### 其他\n[[收藏句子]]\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%8A%A8%E7%94%BB/%E5%8A%A8%E7%94%BB":{"title":"动画","content":"待补充……","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98":{"title":"分布式缓存","content":"\n分布式缓存（Distributed Cache）是一种在分布式计算环境中存储和共享数据的技术。它允许在计算集群的各个节点之间共享数据，以便更快、更高效地进行计算。以下几个关键点可以帮助理解分布式缓存的基本概念：\n\n1. 数据共享：分布式缓存允许在分布式计算节点之间共享数据。这可以确保各计算节点可以访问到相同的数据，从而提高计算性能和一致性。\n\n2. 缓存：分布式缓存通常将数据存储在内存中，以便在计算过程中快速访问。这有助于减少数据访问延迟，提高计算效率。\n\n3. 一致性：分布式缓存需要在不同节点之间维护数据的一致性。这通常需要采用一些同步和数据复制技术，以确保各节点上的数据保持一致。\n\n在 Flink 中，分布式缓存处于辅助性地位，主要用于提高数据访问性能和简化数据共享。Flink 提供了一种简单的分布式缓存机制，允许用户将本地或远程文件作为缓存文件注册到 Flink 任务中。这些缓存文件会被分发到所有计算节点，并在本地文件系统中缓存。然后，在 Flink 任务的处理过程中，用户可以通过分布式缓存 API 快速访问这些缓存文件。\n\n在 Flink 中使用分布式缓存的典型场景包括：\n\n1. 外部数据访问：当 Flink 任务需要访问外部数据（如配置文件、辅助数据等）时，可以使用分布式缓存将这些数据分发到各计算节点，以便在处理过程中快速访问。\n\n2. 数据共享：在进行数据处理时，如果需要在计算节点之间共享部分数据，可以使用分布式缓存将这些数据存储和共享。\n\n总之，分布式缓存在 Flink 中主要用于提高数据访问性能和简化数据共享。通过数据共享、缓存和一致性等特性，分布式缓存可以在分布式计算环境中提高计算性能和一致性。虽然分布式缓存不是 Flink 核心原理的一部分，但它在实际应用中发挥了重要的辅助作用。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80%E9%80%89%E5%9E%8B":{"title":"实时数据开发语言选型","content":"\n\u003e 以下回答均由 GPT4 生成，后续会根据实际使用情况做更改\n\n### 问：做 Flink 实时流数据开发使用 Python 还是 Scala 更好？\n在实时流数据处理中，Apache Flink 提供了对 Java、Scala 和 Python 的支持。然而，在性能和生态系统方面，Scala 和 Java 通常比 Python 更优越。以下是关于在 Flink 实时流数据开发中选择 Python 和 Scala 的一些比较：\n\n1. 性能：\n   - Scala：作为一种运行在 Java 虚拟机（JVM）上的静态类型语言，Scala 具有很好的性能。Scala 与 Java 共享底层运行时，因此在性能方面与 Java 类似。\n   - Python：Python 是一种动态类型语言，通常在性能方面不如 Scala。Flink 使用 PyFlink 支持 Python API，但由于全局解释器锁（GIL）和其他原因，Python 在性能上通常不如 JVM 语言（如 Scala 和 Java）。\n\n2. 生态系统和社区支持：\n   - Scala：Flink 本身是用 Scala 编写的，因此在 API 和功能方面与 Scala 有很好的兼容性。Scala 在大数据和流处理领域有丰富的生态系统和社区支持。\n   - Python：虽然 Flink 支持 Python API，但与 Scala 和 Java 生态系统相比，Python 社区在 Flink 方面的支持相对较弱。\n\n3. 编程模型和语法：\n   - Scala：Scala 是一种功能强大且表达性丰富的编程语言，具有优雅的语法和强大的类型系统。Scala 允许你使用函数式编程和面向对象编程范式，易于编写简洁、可读的代码。\n   - Python：Python 是一种非常流行且易于学习的编程语言，语法简单直观。这使得使用 Python 编写代码变得更加容易，尤其是对于初学者。\n\n综上所述，对于 Flink 实时流数据开发，建议选择 Scala，因为它在性能和生态系统方面具有优势。然而，如果你的团队已经熟悉 Python 且对性能要求不高，可以考虑使用 Python 进行开发。在实际项目中，选择合适的语言取决于团队的技能、项目需求和性能要求。\n\n### 问：Java 和 Scala 相比呢，哪种更适合开发 Flink 实时流数据\n在选择 Java 和 Scala 作为 Flink 实时流数据处理开发语言时，二者各有优势。以下是 Java 和 Scala 的一些比较：\n1. 性能：\n   - Java：Java 是一种运行在 Java 虚拟机（JVM）上的静态类型语言，具有良好的性能。\n   - Scala：Scala 同样运行在 JVM 上，与 Java 共享底层运行时。因此，在性能方面，Java 和 Scala 都具有相似的优势。\n\n2. 生态系统和社区支持：\n   - Java：Java 拥有庞大的生态系统和社区支持，是实时流处理和大数据领域的主要编程语言之一。\n   - Scala：Flink 本身是用 Scala 编写的，因此在 API 和功能方面与 Scala 有很好的兼容性。Scala 同样在大数据和流处理领域拥有丰富的生态系统和社区支持。\n\n3. 编程模型和语法：\n   - Java：Java 是一种面向对象的编程语言，语法相对简单。Java 在 Java 8 及更高版本中引入了对 Lambda 表达式和 Stream API 的支持，使得编写函数式编程风格的代码变得更加简单。\n   - Scala：Scala 是一种功能强大且表达性丰富的编程语言，支持函数式编程和面向对象编程范式。Scala 的语法更加简洁和优雅，使得编写可读性更强的代码变得更加容易。\n\n综上所述，从性能和生态系统的角度看，Java 和 Scala 都适合用于 Flink 实时流数据处理开发。在实际项目中，选择哪种语言取决于团队的技能和编程风格偏好。如果团队熟悉 Java 且更倾向于面向对象编程，那么 Java 可能是一个更好的选择。而如果团队熟悉 Scala 且喜欢函数式编程风格，Scala 可能是更适合的选择。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE-Flink-%E8%B7%AF%E7%BA%BF%E5%9B%BE":{"title":"实时数据 Flink 路线图","content":"\n\u003e 以下是 GPT4 生成的为期三个月的 Flink 实时数据开发的路线图，每个技能及学习的知识都列出了具体时限以及实践内容\n\n了解你的需求。下面是一个针对 Flink 实时数据开发（使用 Java）的学习路线图，其中每个阶段都包含实践内容：\n\n1. Java 基础加强（1 周）：\n   - 学习 Java 面向对象编程（OOP）的概念，如类、对象、继承、封装和多态。\n   - 熟悉 Java 集合框架，如 List、Set、Map 等。\n   - 学习 Java 8 新特性，如 Lambda 表达式、Stream API 和 Optional 类。\n   - 实践：完成一些简单的 Java 编程练习，如实现数据结构和算法。\n\n2. 数据库与 SQL（1 周）：\n   - 学习关系型数据库的基本概念，如表、行、列、主键、外键等。\n   - 学习 SQL 语言，包括 DDL（数据定义语言）、DML（数据操作语言）和查询操作。\n   - 熟悉至少一种关系型数据库管理系统（如 MySQL、PostgreSQL 或 Oracle）的使用。\n   - 实践：创建一个简单的数据库并编写 SQL 查询来实现数据操作。\n\n3. Apache Kafka 简介（3 天）：\n   - 学习 Apache Kafka 的基本概念，如生产者、消费者、主题和分区。\n   - 了解如何使用 Java 编写 Kafka 生产者和消费者。\n   - 实践：搭建一个简单的 Kafka 集群，并使用 Java 编写一个生产者和消费者程序。\n\n4. Apache Flink 入门（2 周）：\n   - 学习 Flink 的核心概念，如流处理、有界和无界数据集、窗口操作和时间处理。\n   - 学习 Flink 的 DataStream API 和 ProcessFunction。\n   - 学习如何使用 Java 进行 Flink 编程。\n   - 实践：使用 Flink 处理 Kafka 中的实时数据，并实现一些简单的数据转换和窗口操作。\n\n5. Flink 中的状态管理和容错（1 周）：\n   - 学习 Flink 中的状态管理和容错机制，如状态后端、检查点和恢复。\n   - 学习如何使用 Flink 的状态 API 进行状态管理。\n   - 实践：在 Flink 程序中使用状态管理，并设置检查点以确保容错。\n\n6. Flink 应用优化与调试（1 周）：\n   - 学习如何监控和调试 Flink 应用。\n   - 了解 Flink 应用的性能调优策略，如资源分配、并行度和缓存。\n   - 实践：监控和调试一个 Flink 实时数据处理应用，并尝试进行性能优化。\n\n7. 实战项目（1 周）：\n   - 根据所学知识，选择一个实际的实时数据处理场景，设计一个 Flink 数据处理项目。\n   - 使用 Java 编写 Flink 程序，处理来自 Kafka 的实时数据流，实现数据清洗、转换、窗口聚合等操作。\n   - 对 Flink 程序进行优化和调试，确保稳定性和性能。\n   - 将处理结果存储到关系型数据库或其他存储系统中。\n\n在学习过程中，请确保将所学知识应用于实际场景，并积累实践经验。参考优质的在线教程、书籍和官方文档，以便更好地学习和巩固知识。此外，可以积极参与 Flink 社区，提问和解答问题，以便更好地学习和巩固知识。\n\n完成这个学习路线图后，你应该能够入门 Flink 实时数据开发并具备完成基础开发任务的能力。不过，请记住，学习是一个持续的过程，你需要不断地实践、探索和更新知识。祝你学习顺利！","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F":{"title":"广播变量","content":"\n广播变量（Broadcast Variables）是一种特殊的数据结构，用于在分布式计算环境中共享数据。在许多大数据处理任务中，广播变量可以有效解决数据共享和同步的问题。以下几个关键点可以帮助理解广播变量的基本概念：\n\n1. 全局共享：广播变量是一个全局共享的数据结构，它可以被所有计算节点访问。这意味着广播变量中的数据可以在整个计算集群中传播和共享，从而确保所有节点可以访问到相同的数据。\n\n2. 只读：广播变量是只读的，这意味着一旦创建并广播，它的内容就不能再修改。这有助于保持数据的一致性，并避免在分布式环境中出现数据竞争和同步问题。\n\n3. 缓存：广播变量通常会在每个计算节点上进行缓存，以便在处理过程中快速访问。这有助于减少数据传输和通信开销，提高计算性能。\n\n在 Flink 中，广播变量处于辅助性地位，主要用于解决数据共享和同步的问题。Flink 支持在 DataStream API 和 DataSet API 中使用广播变量。在 Flink 中使用广播变量的典型场景包括：\n\n1. 参数共享：当需要在分布式计算过程中共享参数或配置信息时，可以使用广播变量。例如，在机器学习任务中，可以将模型参数广播到所有计算节点，以便在进行预测或更新时保持一致性。\n\n2. 小表连接：在进行数据连接操作时，如果其中一个数据集较小，可以将其作为广播变量，以便在所有计算节点上进行高效连接。这有助于减少数据传输和通信开销，提高连接性能。\n\n总之，广播变量在 Flink 中主要用于解决数据共享和同步的问题。通过全局共享、只读和缓存等特性，广播变量可以在分布式计算环境中保持数据的一致性，并提高计算性能。虽然广播变量不是 Flink 核心原理的一部分，但它在实际应用中发挥了重要的辅助作用。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4":{"title":"数据处理时间","content":"\n在 Flink 中，数据处理时间是一个重要概念，它与数据处理过程中的时间相关性有关。Flink 支持两种主要的时间概念：事件时间（Event Time）和处理时间（Processing Time）。这两种时间概念有各自的特点和用途，我们将分别讨论它们。\n\n1. 事件时间（Event Time）：\n事件时间是指数据元素产生时的时间戳。这意味着数据中的每个元素都有一个与之相关的事件时间。这个时间通常是由数据产生源（如传感器、日志记录器等）记录的。Flink 使用水位线（Watermark）机制来处理事件时间。水位线是一种特殊的数据元素，表示某一时刻之前的所有事件已经到达系统。这可以帮助 Flink 确定何时可以对基于事件时间的窗口进行计算和输出。\n\n使用事件时间的优势在于可以保证处理的结果与数据发生的时间顺序一致，即使数据源产生了乱序或延迟数据。这对于需要准确计算基于事件发生时间的统计信息、分析和报告的应用场景非常重要，例如金融交易分析、传感器数据处理等。\n\n2. 处理时间（Processing Time）：\n处理时间是指 Flink 接收到数据元素时的系统时间。处理时间依赖于数据元素到达 Flink 系统的顺序和速度。由于数据到达的顺序可能与实际发生的顺序不同，因此基于处理时间的计算可能会受到数据延迟和乱序的影响。\n\n处理时间的优势在于它简化了时间处理逻辑，因为 Flink 只需考虑当前系统时间。此外，处理时间通常具有较低的延迟，因为它不需要等待水位线或其他时间同步机制。这对于需要快速响应和实时反馈的应用场景非常有用，例如实时监控和报警。\n\n在实际应用中，选择事件时间还是处理时间取决于对结果准确性和处理延迟的要求。如果需要考虑数据发生的时间顺序以获取准确的统计结果，那么事件时间是更好的选择；如果对实时性有较高要求，可以选择处理时间。Flink 也支持同时使用事件时间和处理时间，以便在不同的计算阶段或任务中根据需求选择合适的时间概念。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8A%B6%E6%80%81%E5%92%8C%E5%AE%B9%E9%94%99":{"title":"状态和容错","content":"\n在 Flink 中，状态（State）和容错（Fault Tolerance）是两个关键概念，它们确保了数据处理过程的可靠性和一致性。我们将分别讨论这两个概念：\n\n1. 状态（State）：\n状态是 Flink 任务执行过程中的中间数据。在处理数据流时，任务可能需要根据之前处理过的数据元素来决定如何处理当前的数据元素。这些之前处理过的数据以状态的形式存储。状态可以是简单的计数器、列表，也可以是复杂的数据结构，如哈希表、窗口缓冲区等。\n\nFlink 提供了丰富的状态类型和状态访问接口，以便用户可以根据需要选择合适的状态类型，并在任务中方便地操作状态。Flink 还支持状态后端（State Backend）的概念，用于存储和管理状态数据。状态后端可以是内存、文件系统或分布式存储系统，具体取决于性能、持久性和可扩展性等需求。\n\n2. 容错（Fault Tolerance）：\n容错是指在面对系统故障（如节点宕机、网络故障等）时，Flink 能够保证数据处理的正确性和一致性。为了实现容错，Flink 采用了一种称为“检查点”（Checkpoint）的机制。检查点是 Flink 任务执行过程中的某个时刻的状态快照。Flink 会周期性地将任务的状态保存到检查点中，并将检查点存储到可靠的外部存储系统（如分布式文件系统）。\n\n当发生故障时，Flink 可以从最近的检查点恢复任务执行。这意味着 Flink 会重新加载检查点中的状态数据，并从检查点对应的数据流位置开始重新处理数据。这样，Flink 可以保证在故障发生后，数据处理可以从一个已知的正确状态开始，并保证处理结果的一致性。\n\n为了减小故障恢复时的数据丢失，Flink 还支持端到端的一致性保证，如“精确一次”（Exactly-Once）处理语义。精确一次处理语义确保每个数据元素在 Flink 任务中仅被处理一次，即使在发生故障时。这需要 Flink 与数据源和数据接收方协同工作，以确保数据的正确传输和处理。\n\n总之，状态和容错是 Flink 中两个关键概念，它们确保了数据处理过程的可靠性和一致性。通过使用状态来存储和管理任务的中间数据，以及使用检查点和一致性保证来实现容错，Flink 可以在面对系统故障时","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E8%BD%AC%E8%A1%8C%E6%95%B0%E6%8D%AE%E7%90%86%E7%94%B1":{"title":"转行数据理由","content":"\n就目前就业市场来看前后端这类开发岗位基本上叫苦连天，很多人找不到工作(这是比较真实的情况)，而大数据开发类型的我在网上和有关求职 APP 上看到的抱怨较少而且开的工资普遍比开发岗位要来的多。仔细了解后更是觉得大数据这行会在 AI 蓬勃发展后跟着发展起来，未来会有越来越多的人去了解大数据去学习大数据，毕竟 AI 是绝对离不了数据的，好的 AI 更是如此。\n\n(未完待续……)","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E8%BF%AD%E4%BB%A3%E8%AE%A1%E7%AE%97":{"title":"迭代计算","content":"\n迭代计算是一种反复执行计算过程，直到满足某种终止条件的计算方法。在许多数据处理任务中，迭代计算是一种常见的处理模式，尤其是在图计算、机器学习等领域。迭代计算的基本概念可以通过以下几个关键点来理解：\n\n1. 初始状态：迭代计算开始时，需要一个初始状态。这个状态通常包含一些基本的数据和参数，用于启动迭代过程。\n\n2. 迭代函数：迭代函数是一个用于更新状态的函数。在每次迭代中，迭代函数会根据当前状态计算新的状态。迭代函数可以是简单的数学公式，也可以是复杂的数据处理逻辑。\n\n3. 终止条件：终止条件是一个用于判断迭代是否结束的条件。当终止条件满足时，迭代计算停止，输出最终结果。终止条件可以是迭代次数、误差阈值等。\n\n在 Flink 中，迭代计算是一个重要的处理模式。Flink 支持在数据流中执行迭代计算，这使得 Flink 可以处理那些需要反复执行计算过程的任务，例如图计算、机器学习等。Flink 提供了两种迭代计算模式：批量迭代和流式迭代。\n\n1. 批量迭代（DataSet API）：\nFlink 的 DataSet API 支持批量迭代计算。在这种模式下，迭代计算是基于批处理数据集进行的。批量迭代在每次迭代中处理整个数据集，然后更新状态。当满足终止条件时，批量迭代结束，并输出最终结果。批量迭代适用于那些需要对整个数据集进行全局分析的任务，如图计算、聚类分析等。\n\n2. 流式迭代（DataStream API）：\nFlink 的 DataStream API 支持流式迭代计算。在这种模式下，迭代计算是基于实时数据流进行的。流式迭代可以在数据流中连续处理数据，实现低延迟的迭代计算。流式迭代适用于那些需要实时反馈和动态调整的任务，如在线学习、实时推荐等。\n\n总之，迭代计算在 Flink 中处于重要地位，它使得 Flink 可以处理那些需要反复执行计算过程的任务。通过批量迭代和流式迭代两种模式，Flink 能够满足不同类型的迭代计算需求，提供灵活的数据处理能力。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%A4%A7%E6%95%B0%E6%8D%AE/Flink-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86":{"title":"Flink 基本原理","content":"\nFlink 是一个分布式大数据处理框架，它可以处理大量数据，并提供快速、可靠和实时的数据处理能力。Flink 的基本原理可以通过以下几个简单的概念来理解：\n\n1. 数据流：Flink 使用数据流的概念来表示处理的数据。数据流是一个连续的数据元素序列，这些元素被处理、转换和输出到最终的结果中。简单说，数据流就是从数据源（如文件、数据库等）读取的数据，在 Flink 中经过一系列处理操作，最后输出到目的地（如另一个文件、数据库等）。\n\n2. 节点和任务：**Flink 任务是数据处理的基本单元。一个任务可以是一个简单的数据转换，例如过滤、映射等，也可以是更复杂的操作，例如聚合、排序等**。任务在 Flink 中以节点的形式存在。**节点是构成 Flink 数据流图的基本元素，数据流图是 Flink 对数据处理流程的一种抽象表示**。\n\n3. 并行处理：Flink 具有很好的并行处理能力。这意味着它可以将一个任务划分为多个子任务，在多个计算资源（如 CPU、内存等）上同时处理，以提高整体处理速度。Flink 会自动将任务划分为多个子任务，并行执行，最后将结果汇总。\n\n4. [[大数据/数据处理时间]]：Flink 支持不同的时间概念，包括事件时间（Event Time）和处理时间（Processing Time）。事件时间是数据元素产生的时间，处理时间是 Flink 接收到数据元素的时间。这两种时间概念可用于处理数据时的时间窗口计算，根据实际需求选择合适的时间概念。\n\n5. [[大数据/状态和容错]]：Flink 具有状态管理功能，可以在任务执行过程中存储和管理数据的状态。为了确保数据处理的可靠性，Flink 采用了一种称为“检查点”（Checkpoint）的机制。在执行过程中，Flink 会周期性地将任务的状态保存到外部存储系统，以便在发生故障时从最近的检查点恢复任务执行。\n\n简单来说，Flink 是一个强大的大数据处理框架，它可以处理大量数据，并提供实时、可靠和高效的数据处理能力。通过数据流、节点和任务、并行处理、时间概念和状态管理等核心概念，Flink 能够满足不同类型的数据处理需求。\n\n[[大数据/迭代计算]]\n\n[[大数据/广播变量]]\n\n[[大数据/分布式缓存]]\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%B7%A5%E4%BD%9C%E5%92%8C%E7%94%9F%E6%B4%BB":{"title":"工作和生活","content":"\n根据一年的工作经验和十几年的生活经验来看，这两者如果混为一谈只会让自己的人生更加痛苦除非一开始就打算利用职业生涯来完成自己的理想或者说光凭打工来让自己获取巨额财富。\n\n举个例子来说每天上班的时候不去认真完成工作及时总结经验，仅仅是完成属于自己的那份工作，从来没有想过去扩大自己的影响力或者各方面综合能力，这样从上班的时间里面几乎汲取不到有用的知识而且还会很疲惫。如此一来下班的时间则会疯狂地去娱乐去刺激自己的感官，这样一天下来基本是没有什么长进的，唯一增加的可能就是你的年龄和无效工龄。\n\n更重要的是大部分人都需要通过工作来养活自己和家庭，而工作无论是外企还是中国公司大部分都是一份耕耘一份收获的（仅针对互联网或者相关公司），外企相比于国内公司而言工作内容相对比较机械死板周期拉的很长所以自然而然工作节奏要慢，与此相对的薪水方面就会比较难以和国内工资抗衡，如果过的是低欲望或者说平时不怎么花钱也不想在大城市买房的生活外企则是相当不错的选择但是如果想要在年轻的时候冲一冲赚更多的钱则更建议国内互联网公司。当然还有第三种情况就是选择\"**润**\"出去，一般而言去美国或者加拿大的互联网公司就能实现 WLB，不仅工资高而且不加班福利多。但这种一样有限制条件：你的出生条件得非常好或者说你的硬件条件得好比如说毕业大学，家庭财产良好等等。**所以简单来说就是鱼和熊掌不可兼得，高薪水对应的大概率就是工时长或要求高**。\n\n那么知道了这一点就知道大部分人的大部分时间都需要用去工作或者说被工作占用了，一天除去睡觉刷牙洗澡吃饭的时间后实际上能有12个小时左右，而工作就至少需要占据8个小时时间，也就是说只有4个小时的时间是完全属于自己的，显而易见的是相比于工作直接少了一半。**得出的结论是只要还在依赖工作为金钱来源的话不可避免自己的时间就会变得越来越少，特别是成家立业之后时间基本就完全不属于自己了。有了这个作为前提条件就知道不止是年轻时自己的时间需要好好利用，工作中的时间也一定要利用好**。\n\n### 利用好工作时间\n工作时间的利用好不仅仅是细致地完成属于自己的那部分任务而是在完成工作安排的时候尽量去思考这件事为什么是这样以及下次如何做能够更好地达到效果，并且在遇到问题时及时总结，时间长了再次遇到类似的问题就能够很快地给出解决方案。**这不是为了能够让自己能够在职业生涯里面一帆风顺升职加薪，而是为了能在工作中独当一面成为权威，可以轻松地说服别人从而给自己省事**。而且这样在工作中同样能获得成就感和认同感，时间久了影响力也就自然上去了。有时间在工作时间末尾对一天的工作内容和问题收集排查解决有一个总结和提炼的话是相当重要的时间，不仅知道自己一天做了什么还能温习之前遇到的问题和思考出来的解决方案。\n\n### 利用好自己的时间","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E5%B9%B4%E5%BA%A6%E8%AE%A1%E5%88%92":{"title":"年度计划","content":"\n转眼间2023年也已过半，但是自身感觉却没过多长时间，这可能是因为把时间都放到了一成不变的事情上去并没有取得多大的进步和成就。在之前的 obsidian 仓库中也列出了年度计划，现在要在之前的计划上有更多的增补。\n\n首先就是工作与副业的取舍，这两个于我而言不太可能都能取得较大成功因为我是一个只能把心思花在一个地方的人而且没有天才的头脑。相比于工作，在业余时间找自己喜欢的东西并且坚持下去也绝对不是一件容易的事情，两者最大的区别在于找自己喜欢或者擅长的事情去做不会有那么多质疑和苦恼，难处是坚持下去。对于我这种人而言很难在工作中找到特别大的成就感特别是目前公司是保密无法联网类型的，很多问题和经验无法及时总结到我的知识库中，给我一种很强烈的割裂感：工作就是工作，无法给自己带来个人经验上的成长。而且我也很难忍受一天要一直加班到8点半回到家就是9点的生活，我希望的工作是6点前下班晚上能有更多的时间留给自己，所以我决定选择副业或者说把时间花在自己喜欢和擅长的事情上去。\n\n然后就是爱吃和减脂的取舍，减脂路上最困难的事情就是管住自己的嘴不要乱吃东西，","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%94%B6%E8%97%8F%E5%8F%A5%E5%AD%90":{"title":"收藏句子","content":"\n\u003e 当你停止创造，你的才能就不再重要，你所拥有的只剩下你的品味。而品味会裹挟你，让你排斥他人，变得狭隘。所以，要创造。\n\n\u003e Ars longa, vita brevis\n\u003e 艺术长久，生命短暂\n\n\u003e 你必須從客戶體驗開始，逆向思考應用技術；而不是從技術開始，然後試圖賣給你的客戶。 You've got to start with the customer experience and work backwards to the technology. You can't start with the technology and try to figure out where you're gonna try to sell it. - Steve Jobs\n\n\u003e 从来哭着闹着要走的人，都不是真正会离开的人。真正要离开的那个人，挑一个风和日丽的下午，穿上一件大衣出门，消失在冬日的阳光里，再也没有回来。\n\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%95%99%E7%A8%8B/%E9%9B%86%E7%BE%A4%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8":{"title":"集群和服务器","content":"\n集群（Cluster）和服务器（Server）是计算机网络和分布式系统领域的两个重要概念。它们之间的主要区别在于规模、功能和用途。\n\n### 集群（Cluster）：\n\n1. 规模：**集群通常由多台计算机（服务器）组成**，这些计算机共同协作来完成某个任务或提供某种服务。\n\n2. 功能：集群的主要目的是通过分布式计算来提高性能、可扩展性和可靠性。集群中的多台计算机可以共享计算和存储资源，实现负载均衡和故障切换。\n\n3. 用途：集群广泛应用于大数据处理、高性能计算、高可用服务等领域，例如 Hadoop 集群、Kubernetes 集群等。\n\n### 服务器（Server）：\n\n1. 规模：服务器通常是指一台计算机，它具有较高的性能和可靠性，用于提供某种服务。\n\n2. 功能：服务器的主要功能是响应客户端的请求，处理业务逻辑并返回结果。服务器可以独立运行，也可以作为集群中的一个节点。\n\n3. 用途：服务器广泛应用于网络服务、数据库、文件存储等领域，例如 Web 服务器、数据库服务器等。\n\n总结：集群和服务器的主要区别在于规模，集群是由多台计算机组成，它们共同协作来提供服务，而服务器通常是指一台计算机，独立地提供服务。集群的目的是提高性能、可扩展性和可靠性，而服务器的目的是提供特定的服务。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%95%99%E7%A8%8B/Flink-%E5%B8%B8%E8%A7%81%E6%A6%82%E5%BF%B5":{"title":"Flink 常见概念","content":"`DataStream` 和 `DataStreamSource` 是 Apache Flink 中的两个不同概念，它们在 Flink 作业中起到不同的作用。\n\n1. DataStream：\n\n`DataStream` 是 Apache Flink 的一个核心抽象，用于表示处理流数据的无界数据集。它表示了一个数据集的连续流，并提供了用于转换、过滤、分组、窗口等操作的 API。可以将 `DataStream` 看作是一个流式处理作业的中间或最终结果。\n\n`DataStream` 类提供了用于定义数据流处理作业的各种操作，如 `map`、`filter`、`keyBy`、`window` 等。通过对输入数据应用这些操作，可以构建复杂的 Flink 作业来处理和分析数据。\n\n2. DataStreamSource：\n\n`DataStreamSource` 是一个特殊类型的 `DataStream`，它表示 Flink 作业的输入数据。通常，当您从外部数据源（如 Kafka、文件、套接字等）读取数据时，会创建一个 `DataStreamSource` 实例。`DataStreamSource` 作为数据处理流水线的起点，随后可以在其上应用各种数据处理和分析操作。\n\n创建 `DataStreamSource` 的方法是通过 `StreamExecutionEnvironment` 的一些方法，如 `addSource`、`fromElements`、`fromCollection`、`readTextFile` 等。\n\n总结：\n\n- **`DataStream` 是 Flink 中表示无界数据集的抽象，用于在流处理作业中表示数据流。**\n- **`DataStreamSource` 是一种特殊类型的 `DataStream`，表示 Flink 作业的输入数据。它通常是从外部数据源（如 Kafka、文件、套接字等）读取的数据。**\n\n在 Flink 作业中，首先创建 `DataStreamSource` 来读取输入数据，然后对其应用各种 `DataStream` 操作来处理和分析数据。最后，将处理结果发送到外部存储系统或数据接收器。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%95%99%E7%A8%8B/Kafka":{"title":"Kafka","content":"\nKafka 是一种分布式流处理平台，主要用于构建实时数据流管道和实时应用程序。它可以处理大量数据，并且具有高吞吐量、低延迟和可扩展性等特点。Kafka 由 LinkedIn 开发，后来成为 Apache 开源项目。 \n\n### 基本概念\n1.  Producer：生产者是向 Kafka 发送消息的客户端，通常会将数据源中的数据发送到 Kafka。\n    \n2.  Consumer：消费者是从 Kafka 接收消息的客户端，通常会对接收到的数据进行处理或存储。\n    \n3.  Broker：Kafka [[教程/集群和服务器|集群中的单个服务器]]，负责存储和处理消息。一个 Kafka 集群通常包含多个 Broker。\n    \n4.  Topic：Kafka 中数据的类别或者种类，Producer 向特定的 Topic 发送消息，Consumer 则从 Topic 订阅消息。\n    \n5.  Partition：为了实现高并发和高吞吐量，Topic 被分为多个 Partition，每个 Partition 可以在不同的 Broker 上独立存储和处理。\n    \n6.  Offset：Partition 中的每条消息都有一个唯一的序号，称为 Offset。消费者通过 Offset 记录消费的位置，以便在断开连接后恢复消费。\n\n### 应用场景\n1.  日志收集和处理：Kafka 可以作为一个日志收集系统，将分布式系统中的多个服务的日志统一收集，再进行实时或离线处理。\n    \n2.  消息队列：Kafka 可用作消息队列，实现应用程序之间的解耦合和数据交换。\n    \n3.  实时数据处理：Kafka 可以用于实时数据处理，例如实时监控、实时推荐等场景。\n    \n4.  数据同步：Kafka 可以实现不同数据存储系统间的数据同步，例如将 OLTP 数据库的数据同步到数据仓库。\n    \n5.  事件驱动架构：Kafka 可以作为事件驱动架构的基础设施，用于传输和处理业务事件。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%95%99%E7%A8%8B/obsidian%E6%9C%AC%E5%9C%B0%E5%86%85%E5%AE%B9%E5%90%8C%E6%AD%A5%E5%88%B0%E6%95%B0%E5%AD%97%E8%8A%B1%E5%9B%AD":{"title":"obsidian本地内容同步到数字花园","content":"\n## 准备工作\n1. 首先 fork 两个模板项目作为参考","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%9C%89%E8%B6%A3%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86":{"title":"有趣的小知识","content":"\n\u003e [!NOTE] Question\n\u003e \n理发店外的蓝白红转机的来源是什么\n\n蓝白红的理发店旋转柱（barber pole）起源于中世纪的欧洲。在那时，理发师不仅剪发，还承担了一些外科手术的职责，例如拔牙、血脉放血等。这些职责被称为“理发外科医生”。蓝白红的旋转柱象征着他们的这些职责。\n\n其中，红色代表血液，因为在中世纪，放血疗法（bloodletting）是一种常见的治疗方式。白色代表绷带，用于包扎伤口。蓝色可能源于美国独立战争后期，蓝色被添加以表示美国的颜色。这三种颜色交织在一起，形成了今天理发店前的蓝白红旋转柱标志。\n\n如今，尽管理发师的工作已经与外科手术完全分离，但这个传统的标志仍然沿用至今，成为了理发店的象征。\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-09":{"title":"2023-04-09","content":"\n每天花在电脑上的时间实在是太长了，准确来说是电脑消遣方面。上电脑无非就是几件事情：看视频消遣、玩游戏消遣、看 TradingView 和 Twitter 消磨时光，除此以外几乎不会拿电脑做任何正事或者是有意义的事情。不论是平时还是周末，几乎都只是在电脑前坐着然后做上述几件事情来消磨时光，这在我看来很可悲，因为这样做的意义也只是让思维僵化然后循规蹈矩地做这几件已经习以为常的事情。\n\n1. 工作时间内专心一些，最好把时间都放入到写代码完成业务中而不是抱着完成任务的心态去做工作\n2. 减少面对电脑或者手机的时间增加看纸质书的时间，过去几个月几乎没有翻过书，没有看书的日子就是没头苍蝇很迷茫的日子，只能靠电脑来消磨时光\n3. 在自己的专业领域投入更多的时间，不仅仅是技术上需要精进更重要的是理解自己为何而工作，什么样的工作能让自己持之以恒地做下去不会一段时间一个想法","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-10":{"title":"2023-04-10","content":"学习网页上传文件并处理功能[[网页上传原理]]，对于上传的整体流程有了更为深入的理解","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-11":{"title":"2023-04-11","content":"\n### 工作心态和个人心态的平衡\n工作中很难避免地会出现很多指标，当指标变得越来越多的时候人的心态就会出现变化特别是指标变成强制而且和绩效挂钩的时候，能在工作中全身心投入到代码开发或者学习提升的时间变得越来越少，而时间基本都放到如何将指标提升上去这一行为中。\n\n而实际上指标完成率高和是否把事情做好基本没有太大的关系，很多时候员工只会想方设法地做一些毫无意义的事情或者瞒报虚报来把指标提高，特别是领导特别重视或者说本身就是靠着这种方法上位的人则更是这样。久而久之就会发现只要有问题就会想法设法地拉会议提出解决方法然后要求你闭环，但是会议的主题却并不是当机立断地结合实际问题把解决问题的方法确定下来而是想法设法出文档出方案要求用数据或者指标闭环来确保这个事情确实得到了解决，最终的结果大多就是 wiki 文档或者 wps 云文档上又多出了一份垃圾来增加搜索真正有用文档的难度。\n\n那么如何平衡自己工作时的心态以及平时生活的心态来让自己不要把怒气代入到工作中呢？我目前的心得体验是工作的时候尽量认真对待，但是需要每天从工作时间抽出固定的时间留给自己去做总结和提炼(例如今天写业务时碰到的问题是如何解决的，通过这个问题我学到了什么)，遇到指标上的事情照做不误就是了因为是公司要求的而又是它给我钱，反正我工作时间就这么多，其他事情做不完直接和领导说就是不要自己烦扰自己。最主要的就是每天要有所收获，无论是工作上还是工作外，这样才有持续生活的动力才不会觉得自己的生活就只有工作。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-12":{"title":"2023-04-12","content":"\n今天在工作中没有做总结，工作中主要做了两件事：帮其他组重建 React 项目，搭了包括配置项、请求封装、git 钩子等等脚手架，整体基于 umimax。跟进测试问题，修复了负数数字没有动画的问题。\n\n使用 umimax 最新版的时候遇到了两个之前没碰到过的问题：\n1. VS Code 自带 [[TypeScript]] 编译器可能和项目安装的 TypeScript 版本不一致，如果项目内版本更高一些则会导致 tsconfig.json 配置文件报错从而导致整个项目的导入都有问题，有两个解决方案，一个是降级项目内的 TypeScript 版本另外一个就是设置 VS Code 的 TypeScript 版本，一般推荐第二种。第二种设置之后会在项目顶端生成 .vscode 文件夹，里面放着 setting.json 配置文件指定了 VS Code 配置项。\n2. 作业条请求封装的问题，之前从来没接触过作业条后端所以今天相当于重新学习了这种请求体如何封装以及返回的参数是什么，由于项目内基本都是作业条请求所以无需做过剩的封装，做一层简单的错误处理以及拿到响应体里面需要的数据即可。\n\n做事要认真这个没问题，但是同时也要结合实际业务场景去考虑一些事情是否需要做的如此复杂例如考虑的请求封装，由于项目内全是作业条请求所以基本不需要做过多的封装，完成后时间可以投入到其他事情中去。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-14":{"title":"2023-04-14","content":"\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-16":{"title":"2023-04-16","content":"\n最近的生活状态实在不太规律，经常性的1-2点睡觉然后7点半左右起床，平均下来每天的睡眠时间可能只有6个小时不到。而且由于中午55才下班，回去做完饭洗完碗可能都会一点过不少了，这个只能自己适应：要不就午睡时间缩短一点要不就提前晚上做好第二天的饭然后加热就行。\n\n最大的问题是我平均睡眠时间短是因为玩游戏的时间太多了，或者说固态化三件套时间太多了：基本就是 Youtube、Twitter、Tradingview 三个软件之间来回切换，然后除此以外的时间都在玩 Apex，基本没有时间放在认真读书和研究技能上的事情。减脂这件事情也因为不规律的生活导致进度拖延：这两周体重基本没有变化，虽然有持续在运动(因为吃的东西方面没有控制，经常中午不想做饭了就去吃麦当劳)。\n\n最近的表现实在是太不尽如人意，随着年龄的越来越大逐渐发现有些事情无法改变，但是有一点是我可以肯定的：只要持之以恒地做某件事情，那么这件事情在手中就会做的越来越好，起初可能完全带来不了任何收益而且会占用大量的时间但是随着时间的推进能做到的事情要远超自己想象。**我会先从放弃网游和看没营养的视频开始把时间慢慢地挪出来做更有意义的事情。**\n\n明天要做的最重要的事情就是把 [[年度计划]] 都大致列一个，看看哪些事情对目前的自己是最重要的，如何去达成它们，不在乎最终达成的结果而是在意过程如何。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-17":{"title":"2023-04-17","content":"\n最近工作上需要使用代码开发重构之前使用可视化平台开发的作业，[[大数据/实时数据开发语言选型]]上斟酌了很久，最后决定采用 Java 开发。组内没有任何使用代码开发数据的经验，前期选型语言上就花费了大量的时间，需要慢慢结合实践去熟悉 Java 的使用以及流数据代码开发。为此也根据 GPT4 列出实时数据代码开发的[[大数据/实时数据 Flink 路线图|路线图]]。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-18":{"title":"2023-04-18","content":"\n[[大数据/Flink 基本原理]] 由 GPT4 初步生成，后续根据学习内容及时调整。接下来一段时间就把时间和精力主要投入到大数据开发上面。根据网上的评价和招聘情况可以看出大数据方面非常缺人而开发岗则极度火热，究其原因可能是大数据相关的知识大而杂但是到岗位和业务之后又会变得细而精，学习起来不容易上手而且国内没有太多相关的中文文档，网上的知识也是寥寥可数，培训班对于这个方向也没有像前后端那样完整的培训体系。\n\n之后会把时间投入到数据学习中，[[大数据/转行数据理由|为什么呢]]？大数据开发在 AI 蓬勃发展之后也会有一大波进步的空间，现在国内在大数据开发上精通的人相对开发岗位的人来说少得多，而且中文文档和培训资料也是少得多，就身边人就业情况来说目前还没听说过大数据开发这个方向的，大部分都是做游戏或者普通开发岗。\n\n大数据开发要学习的内容和知识点相当多，基本计算机内容都会涵盖到包括操作系统、Linux 命令、容器启停、集群运维还有各种持久化层例如 ES、Redis、Hbase、ClickHouse 等等。仅拿前端来对比，要比前端熟悉和会的知识点多得多，实际上前端主要掌握 JS、CSS 两件套就够了，但数据开发要掌握的却是整个计算机知识体系。我喜欢做有挑战的事情，最近更是希望自己做能长期坚持下去的事情，而大数据开发则是一个很好的方向，**但是要同时切记不管什么知识能用到生活中、工作中为人类社会带来价值的事情才是有意义的知识，不要一味地钻研知识从而掉入了唯知识论的思维中，觉得万般皆下品，惟有读书高。不去做能为他人带来价值为社会带来价值的事情，长期下来只会觉得内心空虚**。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-19":{"title":"2023-04-19","content":"\n由于经常逛推而且收藏一些 thread，但是 twitter 看历史以及收藏的功能做的实在是太烂而且格式也不统一并且不支持发送长文所以基本上保存就等于学会，实际上基本不会再点开一次，很多优秀的文章也因此没有机会再完整阅读了，最近想利用浏览器插件在推特保存 thread 过后自动向 github仓库提交文件，然后后续本地仓库 pull 一下就行(最好设置一个自动化流程，每天早上自动同步)。该想法已经被否决(已经有了成熟的产品 readwise，基本集成了网页端全部的应用，都可以做笔记然后导出到笔记软件上)\n\n[[收藏句子]]\n\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-22":{"title":"2023-04-22","content":"\n安装了一个可以支持大部分自定义的主题：[[obsidian/Anuppuccin]]，通过 Style Setting 插件来自定义大部分样式包括主题色、MD 文件样式、Layout 样式等等，可以说有非常高的自定义能力了，如果后续有时间可以出一个教程来使用这款主题。\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-23":{"title":"2023-04-23","content":"\n昨天熬夜主要搞了 Obsidian 的美化操作，将主题和字体设置到了自己舒服的程度，之前一直使用默认的界面感觉并不是很舒服，而且很多 **markdown 展示** 都不完善例如大标题只有大小没有颜色的区别让人分不清楚，同理**加粗**和*斜体*也是这样。之前觉得 obsidian 没有插件也能很好的使用，但是就目前的情况来说少了一些辅助插件去写文章就会时不时的多出一些心智负担，比如说经常忘记一些 md 语法像是插入图片、插入待办等等，这个时候有一个辅助 md 提示就会方便很多。**所以有的时候插件并不是越少越好也不是越多越好，仅仅取决于供需关系**。如果你希望写作时的负担小一些而且使用插件并不会大于不使用的心智负担就尽可能的去使用插件来为自己所用。\n\n### 关于 obsidian 使用的插件\n1. [[Calendar]]\n2. Obsidian git\n3. [[Outliner]]\n4. [[Style Settings]]","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-24":{"title":"2023-04-24","content":"\n看完了[[漫画/亲爱的我包含杀意]]，相当优秀的悬疑智斗漫画，最后的主题也一并升华。\n\n最近漫画看的实在有点太多了，基本都是悬疑智斗类，搞得自己在晚上的时候也有点疑神疑鬼的。看这类漫画的意义一方面是满足自己推理和猜测的好奇心另一方面是观察人性之恶到底能有多么没有底线。\n\n今天又装了 [[tracker]] 和 [[cMenu]] 两款插件，感觉对于我的 obsidian 而言又多了便捷性和统计性。\n\n### 工作\n- [x] 数据 DDH 迁移，审批通过后 PMS 打包\n- [x] 文档迁移完成，检查无语病无展示问题后提交到群里一起过一下\n- [x] 数据地图一批次功能自测提测\n- [x] 有时间继续开发重构 Flink 作业代码\n\n### 生活\n- [x] 使用番茄钟来规范自己的专注时间\n- [x] 如交易一样，凡事都应该至少有一份粗略的计划，在什么时间段该干什么应该都是大概列好的，这样能得到什么的结果也是大概知道的，否则就如无头苍蝇般根本不知道明天未来会发生什么，进步也就因此停止\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-25":{"title":"2023-04-25","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e Honesty is the best policy.\n\u003e — \u003ccite\u003eBenjamin Franklin\u003c/cite\u003e\n\u003e \n\u003e ![photo by Gracia Dharma on Unsplash](https://images.unsplash.com/photo-1607604276583-eef5d076aa5f?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODIzNTY0Mjg\u0026ixlib=rb-4.0.3\u0026q=85)\n\n根据 [[obsidian/Templater]] 插件重新生成了模板文档，并且给主要的模板文档添加了快捷键。\n[[SQL]]\n### 工作\n- [x] PO 演示，功能提测\n- [x] 完善 Flink 代码，至少完成过滤方法、日期格式化、判断子户新增\n- [x] 完善数据集市规范文档\n\n### 生活\n- [x] [[教程/Kafka]] 概念学习， 对于基本概念有一个更为完整的认知\n- [ ] 对交易计划和执行计划有一个更为全面的规则和认知\n- [ ] ~~锻炼身体，恢复到正常饮食~~ 打了羽毛球肌肉酸痛今天休息一天\n- [x] 学校档案问题\n- [x] 找泽丰和 yoga 确认一下香港入境问题\n\n🍅 星期二, 四月 25 2023, 10:11 上午\n🍅 星期二, 四月 25 2023, 11:00 上午\n🍅 星期二, 四月 25 2023, 11:30 中午\n\n🍅 星期二, 四月 25 2023, 3:58 下午\n🍅 星期二, 四月 25 2023, 4:35 下午\n🍅 星期二, 四月 25 2023, 5:06 下午\n🍅 星期二, 四月 25 2023, 5:30 晚上\n\n🍅 星期二, 四月 25 2023, 11:00 晚上","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-26":{"title":"2023-04-26","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e He that is giddy thinks the world turns round.\n\u003e — \u003ccite\u003eWilliam Shakespeare\u003c/cite\u003e\n\u003e \n\u003e ![photo by Trayan on Unsplash](https://images.unsplash.com/photo-1564403848767-9db2a39c65aa?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODI0NDU4ODM\u0026ixlib=rb-4.0.3\u0026q=85)\n\n[[git 常见问题]]\n\n### 工作\n- [x] 财资云待授权功能开发联调\n- [x] 报告图片替换功能开发联调\n- [x] 商机 React 项目重构，拉会说明重构流程及项目结构，申请码云公共仓库以及构建流水线\n\n### 生活\n- [x] 早睡早起（最多1点左右睡觉，每天2-3点睡觉有点影响第二天的安排）\n- [x] 锻炼身体，控制饮食\n- [ ] ~~[[教程/Kafka]] 概念继续学习，上手直接实操建立一个 Kafka 集群，然后作为生产者往集群中添加数据作为消费者消费集群中的数据~~ 未完成，时间用来看漫画了\n- [ ] ~~整理下 obsidian 插件，对所使用的插件做个大体的介绍~~ 未完成，时间用来看漫画了\n\n\n🍅 星期三, 四月 26 2023, 10:00 上午\n🍅 星期三, 四月 26 2023, 10:30 上午\n🍅 星期三, 四月 26 2023, 11:00 上午\n\n\n🍅 星期三, 四月 26 2023, 2:51 下午\n🍅 星期三, 四月 26 2023, 3:41 下午\n🍅 星期三, 四月 26 2023, 4:25 下午\n🍅 星期三, 四月 26 2023, 4:50 下午\n🍅 星期三, 四月 26 2023, 5:22 下午\n🍅 星期三, 四月 26 2023, 5:52 下午","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-27":{"title":"2023-04-27","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e I think that we have a great opportunity to impart our wisdom and our knowledge and our experience to this younger generation. It may be different times, but experience transcends(超越) time, and wisdom transcends time.\n\u003e — \u003ccite\u003eVictoria Osteen\u003c/cite\u003e\n\u003e \n\u003e ![photo by Redd F on Unsplash](https://images.unsplash.com/photo-1505069190533-da1c9af13346?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODI1MjU2MzA\u0026ixlib=rb-4.0.3\u0026q=85)\n\n目前觉得应该把[[工作和生活]]**上做的事情分开**，工作上或者说业务上所需要花费的时间基本上不会超过工作时间，哪怕让你从前端去干数据、后端也不会有多大影响，顶多前期需要稍微多花费一点时间去做熟悉别人的代码和新的开发语言，但大部分的知识都是共通的。\n[[香港银行卡办理]]\n\n\n### 工作\n- [x] Hbase 连接和输出\n- [x] CRMIT 投产验证清单\n- [ ] ~~Flink 代码重构完成左半部分的逻辑重写~~\n- [ ] ~~北斗见微日志对接~~\n- [x] 工作内容回顾和问题总结以及思考过程\n\n几乎一整天都耗在行内 HBase 的连接与测试上，而且最后结果还不是很理想一天下来几乎没有干成什么事情。我觉得这种事情完全可以避免，我一开始并不熟悉 HBase 但是这不会特别妨碍我去做查询写入的工具类编写。但问题在于这个东西的连接和行内 RDM 平台绑定地很深（因为有很多专业术语），非常熟悉 RDM 平台的人去做这个本地连接远程 HBase 则是更有效率的事情例如之前早早就进行数据开发的同事。\n\n再有一个就是遇到问题无法解决或者说无法短期内解决的话就去找 leader 商量，给出自己的理由和解决方案，只要不是太过离谱相信都能帮你解决问题，毕竟他们的作用就是合理分配资源调度资源然后给予帮助和权限。\n\n### 生活\n- [x] 锻炼身体，健康饮食  饮食没有非常健康，中午吃的面晚上吃的麦当劳\n- [x] 网页资源整理，去除掉大部分不需要的资源和收藏\n- [ ] ~~obsidian 插件整理和大纲编写~~ 这个先暂延，近几天要放假需要安排行程\n- [x] 考虑假期的安排，做一下[[行程规划]]和酒店预定等工作，这个时间估计只能忍痛被宰了\n- [ ] 打扫房间，整理个人物品\n- [ ] obsidian 作为电子阅读器的可能性以及 readwise 的可能性\n\n\n🍅 星期四, 四月 27 2023, 9:46 上午\n🍅 星期四, 四月 27 2023, 10:22 上午\n🍅 星期四, 四月 27 2023, 11:01 上午\n🍅 星期四, 四月 27 2023, 11:38 中午\n🍅 星期四, 四月 27 2023, 2:38 下午\n🍅 星期四, 四月 27 2023, 3:12 下午\n🍅 星期四, 四月 27 2023, 10:01 晚上\n🍅 星期四, 四月 27 2023, 10:56 晚上\n🍅 星期四, 四月 27 2023, 11:34 晚上","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-28":{"title":"2023-04-28","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e Experience is not what happens to a man. It is what a man does with what happens to him.\n\u003e — \u003ccite\u003eAldous Huxley\u003c/cite\u003e\n\u003e \n\u003e ![photo by Sora Sagano on Unsplash](https://images.unsplash.com/photo-1524413840807-0c3cb6fa808d?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODI2NDM2NTg\u0026ixlib=rb-4.0.3\u0026q=85)\n\n[[Youtube 视频下载|Youtube 下载]]\n[[FFmpeg]]\n### 工作\n- [x] 完成见微北斗配置\n- [ ] ~~待授权逻辑继续编写~~\n- [x] 提测财资云部分功能\n\n### 生活\n- [x] 锻炼身体，健康饮食\n- [x] 打扫房间，整理个人物品，清理旅游需要带上的东西\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-29":{"title":"2023-04-29","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e The journey of a thousand miles begins with one step.\n\u003e — \u003ccite\u003eLaozi\u003c/cite\u003e\n\u003e \n\u003e ![photo by Levon Vardanyan on Unsplash](https://images.unsplash.com/photo-1600758208050-a22f17dc5bb9?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODI3MDIwMDk\u0026ixlib=rb-4.0.3\u0026q=85)\n\n### 生活\n- [x] 整理房间，打扫房间\n- [x] 剪指甲，整理仪容\n- [ ] 研究 readwise 的使用，平时经常会看一些文章和推，收藏后及时总结是很好\n- [ ] 读书《科技想要什么》\n- [x] 开始编写 bilibili 根据 TAG 或者视频内容自动评论系统\n- [ ] ~~自己做中饭和午饭，中饭决定吃土豆肥牛+鸡腿肉+上海青，晚饭吃牛排，锻炼身体~~\n\n🍅 星期六, 四月 29 2023, 2:39 下午\n🍅 星期六, 四月 29 2023, 11:26 晚上","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-04-30":{"title":"2023-04-30","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e We don't stop playing because we grow old; we grow old because we stop playing.\n\u003e — \u003ccite\u003eBernard Shaw\u003c/cite\u003e\n\u003e \n\u003e ![photo by Ian Valerio on Unsplash](https://images.unsplash.com/photo-1519638399535-1b036603ac77?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODI3ODUwMTI\u0026ixlib=rb-4.0.3\u0026q=85)\n\n### 生活\n- [ ] 开源指南，抽空读一下\n- [x] 提前保存好几篇小红书指南，去一趟深圳值得去的地方：最好限制在花园、公园、有树木海滩的地方\n- [x] 晚上宾馆锻炼不能停，顺便安排一下第二天的行程\n- [ ] 继续读《科技想要什么》\n- [x] 选好了电脑用的入耳式耳机，夏天头戴式耳机实在是太热了而且使用也不方便还会破坏发型\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-05-01":{"title":"2023-05-01","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e Divide each difficulty into as many parts as is feasible and necessary to resolve it.\n\u003e — \u003ccite\u003eRené Descartes\u003c/cite\u003e\n\u003e \n\u003e ![photo by Aleksandr Popov on Unsplash](https://images.unsplash.com/photo-1504253492562-cbc4dc540fcb?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODI5MDc2NDc\u0026ixlib=rb-4.0.3\u0026q=85)\n\n### 生活\n- [ ] 吃蘩楼早茶\n- [ ] 和述奇爬山\n- [ ] 晚上和泽丰一起吃饭\n- [ ] \n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-05-05":{"title":"2023-05-05","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e In all things of nature there is something of the marvelous.\n\u003e — \u003ccite\u003eAristotle\u003c/cite\u003e\n\u003e \n\u003e ![photo by Agathe on Unsplash](https://images.unsplash.com/photo-1525230071276-4a87f42f469e?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODMyMTc3NzE\u0026ixlib=rb-4.0.3\u0026q=85)\n\n[[python 虚拟环境]]\n### 工作\n- [x] 修复财资云一批次提的 BUG\n- [ ] 财资云待授权代码完善，HBase 的连接及使用\n- [x] 好好工作，认真生活，学习与人为善\n- [x] 项目回顾会\n\n### 生活\n- [x] 继续B站自动评论功能开发\n- [ ] 算法的意义及重要性\n\n🍅 星期五, 五月 05 2023, 9:45 上午\n🍅 星期五, 五月 05 2023, 10:16 上午\n🍅 星期五, 五月 05 2023, 11:17 上午\n🍅 星期五, 五月 05 2023, 11:22 晚上","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-05-06":{"title":"2023-05-06","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e An appeaser is one who feeds a crocodile, hoping it will eat him last.\n\u003e — \u003ccite\u003eWinston Churchill\u003c/cite\u003e\n\u003e \n\u003e ![photo by Ian Valerio on Unsplash](https://images.unsplash.com/photo-1519638399535-1b036603ac77?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODMzMzQ3ODU\u0026ixlib=rb-4.0.3\u0026q=85)\n\n### 工作\n- [ ] HBase 讲解顺序以及实机演示\n- [ ] 待授权代码开发\n- [ ] 下午 Java 代码检视\n\n### 生活\n- [ ] 重构之前的 js 代码改为 ts，并理解两种语言写 nodejs 之间的区别\n- [ ] 至少完成视频搜索及过滤的功能，过滤条件主要为播放量1000以上、Tag 包括关键词、评论数大于10等等\n- [ ] 算法的重要性以及常用的数据结构，使用 GPT4 学习\n\n\n🍅 星期六, 五月 06 2023, 12:18 凌晨\n🍅 星期六, 五月 06 2023, 9:30 上午\n🍅 星期六, 五月 06 2023, 10:08 上午\n\n🍅 星期六, 五月 06 2023, 2:48 下午\n🍅 星期六, 五月 06 2023, 4:04 下午\n🍅 星期六, 五月 06 2023, 4:43 下午","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-05-07":{"title":"2023-05-07","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e You are always free to change your mind and choose a different future, or a different past.\n\u003e — \u003ccite\u003eRichard Bach\u003c/cite\u003e\n\u003e \n\u003e ![photo by David Edelstein on Unsplash](https://images.unsplash.com/photo-1526481280693-3bfa7568e0f3?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODMzOTk3Mjc\u0026ixlib=rb-4.0.3\u0026q=85)\n\n[[Switch 模拟器]]\n- [x] 研究两款 Switch 模拟器，运行星之卡比豪华版对比下效果\n- [ ] 重构自动评论系统代码变为 TypeScript，搞清楚和 JavaScript 的区别\n- [ ] 看书《科技想要什么》\n- [x] 运动+健身\n🍅 星期日, 五月 07 2023, 11:46 晚上","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%AF%8F%E6%97%A5/2023-05-08":{"title":"2023-05-08","content":"\u003e [!NOTE] Daily Quote\n\u003e \u003e There is no scarcity of opportunity to make a living at what you love; there's only scarcity of resolve to make it happen.\n\u003e — \u003ccite\u003eWayne Dyer\u003c/cite\u003e\n\u003e \n\u003e ![photo by Ryan Klaus on Unsplash](https://images.unsplash.com/photo-1650179745028-e98aa3434b10?crop=entropy\u0026cs=srgb\u0026fm=jpg\u0026ixid=MnwzNjM5Nzd8MHwxfHJhbmRvbXx8fHx8fHx8fDE2ODM1MDk1MjU\u0026ixlib=rb-4.0.3\u0026q=85)\n\n### 工作\n- [ ] 待授权代码编写\n- [ ] 24h 适配代码提交\n\n### 生活\n- [ ] 自动评论系统代码转为 typescript 并且能在本地自动热更新编译\n- [ ] 从今天开始养成每天看15min书的习惯，包括但不限于金融、创业、产品相关的事情\n\n\n🍅 星期一, 五月 08 2023, 10:32 上午\r🍅 星期一, 五月 08 2023, 11:28 上午","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%BC%AB%E7%94%BB/%E4%BA%B2%E7%88%B1%E7%9A%84%E6%88%91%E5%8C%85%E5%90%AB%E6%9D%80%E6%84%8F":{"title":"亲爱的我包含杀意","content":"\n未完待续……","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%BC%AB%E7%94%BB/%E6%88%91%E5%BF%83%E9%87%8C%E5%8D%B1%E9%99%A9%E7%9A%84%E4%B8%9C%E8%A5%BF":{"title":"我心里危险的东西","content":"\n真正的熬夜看完了这本漫画，大抵算是人生中真正意义上的第一次熬夜(指超过早上八点不睡觉)","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E6%BC%AB%E7%94%BB/Anime-%E8%8A%B1%E5%9B%AD":{"title":"Anime 花园","content":"\n这里是 Anime 花园，请多指教！\n[[漫画/我心里危险的东西]]\n[[漫画/亲爱的我包含杀意]]","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E7%BD%91%E9%A1%B5%E4%B8%8A%E4%BC%A0%E5%8E%9F%E7%90%86":{"title":"网页上传原理","content":"**FileReader** 对象用于读取用户在浏览器中选择的文件。这在处理文件上传、读取文件内容以显示在页面上或解析文件数据时非常有用。\n\nFileReader 对象包含了一系列方法和事件，让你能够以不同的方式读取文件数据，例如：\n1.  readAsText(file, encoding): 以文本形式读取文件内容，可以指定编码方式，通常是 \"UTF-8\"。\n2.  readAsDataURL(file): 读取文件内容并将其转换为 base64 编码的 data URL，这在显示图片或其他媒体文件时非常有用。\n3.  readAsArrayBuffer(file): 以 ArrayBuffer 形式读取文件内容，这在处理二进制数据时非常有用，比如图像、音频或视频文件。\n\nFileReader 对象还包含了一些事件，例如：\n1.  onload: 当文件读取操作成功完成时触发。\n2.  onerror: 当文件读取操作失败时触发。\n3.  onprogress: 当文件读取操作正在进行时触发。\n\n### 示例代码\n``` html\n\u003cinput type=\"file\" id=\"inputImage\"\u003e\n\u003cimg id=\"displayImage\" alt=\"Selected image\"\u003e\n```\n\n\n``` javascript\nconst inputImage = document.getElementById('inputImage');\nconst displayImage = document.getElementById('displayImage');\n\ninputImage.addEventListener('change', (event) =\u003e {\n  const file = event.target.files[0]; // 获取用户选择的第一个文件\n  if (file \u0026\u0026 file.type.startsWith('image/')) { // 确保文件是图像\n    const reader = new FileReader();\n\n    // 当读取操作成功完成时，将图片的data URL设置为\u003cimg\u003e标签的src属性\n    reader.onload = (e) =\u003e {\n      displayImage.src = e.target.result;\n    };\n\n    // 使用readAsDataURL方法读取图像文件\n    reader.readAsDataURL(file);\n  } else {\n    alert('Please select a valid image file.');\n  }\n});\n\n```\n\n`reader.readAsDataURL(file)`是必不可少的。实际上，`e.target.result`中的base64编码的图片数据是在`reader.readAsDataURL(file)`执行后得到的。`readAsDataURL()`方法是`FileReader`对象用来读取文件内容并将其转换为base64编码的DataURL的函数。当这个方法被调用时，FileReader对象会开始读取指定的文件并在完成时触发`onload`事件。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E8%A1%8C%E7%A8%8B%E8%A7%84%E5%88%92":{"title":"行程规划","content":"\n周六晚上八点半飞机几乎十二点到达，因为到达时间太晚了晚上就近在机场附近酒店住了。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/%E9%A6%99%E6%B8%AF%E9%93%B6%E8%A1%8C%E5%8D%A1%E5%8A%9E%E7%90%86":{"title":"香港银行卡办理","content":"### 银行排名\n1. 中国银行(香港)\n2. 渣打银行\n3. 恒生银行\n4. 招商永隆银行\n\n### 准备资料\n- 港澳通行证\n- 身份证\n- 入境小纸条\n- 地址证明(信用卡账单)\n- 10000 港币(非必须)\n- 资产证明\n\n先去申请中国银行，实在不行申请众安网络银行","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/FFmpeg":{"title":"FFmpeg","content":"\n\n``` powershell\n# MP4 文件转为 AVI 文件\nffmpeg -i input.mp4 output.avi\n\n# M4A 音频转为 FLAC 音频\nffmpeg -i input.m4a -c:a flac output.flac\n```\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/SQL":{"title":"SQL","content":"\n### ROW_NUMBER() OVER\n在 SQL 查询中，当使用 `PARTITION BY field1, field2` 时，实际上是根据 `field1` 和 `field2` 的值对数据进行分组。这里的组合并不是将两个字段的值直接拼接，而是将具有相同 `field1` 和 `field2` 值的行分到同一个分区。\n\n例如，假设有以下表格数据：\n\n| id | field1 | field2 | field3 |\n|----|--------|--------|--------|\n| 1  | A      | X      | 100    |\n| 2  | A      | X      | 200    |\n| 3  | A      | Y      | 300    |\n| 4  | B      | X      | 400    |\n| 5  | B      | Y      | 500    |\n| 6  | B      | Y      | 600    |\n\n在这个表格中，如果你使用 `PARTITION BY field1, field2`，数据会被划分为以下分区：\n\n1. 分区 1：包含具有 field1 = A 和 field2 = X 的行 (id: 1, 2)\n2. 分区 2：包含具有 field1 = A 和 field2 = Y 的行 (id: 3)\n3. 分区 3：包含具有 field1 = B 和 field2 = X 的行 (id: 4)\n4. 分区 4：包含具有 field1 = B 和 field2 = Y 的行 (id: 5, 6)\n\n在每个分区内，可以对其他字段（如 `field3`）进行排序并分配行号。例如，如果你使用 `ROW_NUMBER() OVER (PARTITION BY field1, field2 ORDER BY field3 DESC)`，查询结果将如下：\n\n| id | field1 | field2 | field3 | row_number |\n|----|--------|--------|--------|------------|\n| 2  | A      | X      | 200    | 1          |\n| 1  | A      | X      | 100    | 2          |\n| 3  | A      | Y      | 300    | 1          |\n| 4  | B      | X      | 400    | 1          |\n| 6  | B      | Y      | 600    | 1          |\n| 5  | B      | Y      | 500    | 2          |\n\n这里可以看到，每个分区内的行都根据 `field3` 的值进行了降序排序，并分配了唯一的行号。","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/Switch-%E6%A8%A1%E6%8B%9F%E5%99%A8":{"title":"Switch 模拟器","content":"\n\n\u003e [!NOTE] 概览\n\u003e 目前 Switch 模拟器主要就是 yuzu 和 ryujinx 两款，不少人说 Cemu 不是模拟器吗？那个是 WiiU 的模拟器，实际上旷野之息是 WiiU 游戏后面被移植到 Switch 上去的。目前几乎所有 Switch 模拟器都是开源的，所以任天堂起诉不了它们\n\n### yuzu\n大部分 Switch 游戏都能在 yuzu 模拟器上正常运行，并且支持 xci 和 nsp 类型的游戏文件，有中文 GUI等等。\n### ryujinx","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/Tracker":{"title":"Tracker","content":"\n``` tracker\nsearchType: text\nsearchTarget: 🍅\nfolder: /每日\nstartDate: -1M\nendDate: 0d\nfitPanelWidth: false\nfixedScale: 1.3\nline:\n\ttitle: 番茄钟\n\tyAxisLabel: 个数\n\tyAxisUnit: 25min/个\n\tlineColor: yellow\n```\n```tracker\nsearchType: frontmatter\nsearchTarget: pomodoro\nfolder: 每日\ndatasetName: 番茄钟\nsummary:\n\ttemplate: \"平均番茄钟个数：{{average()}}\"\n```\n\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/TypeScript":{"title":"TypeScript","content":"\n待完善","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/Youtube-%E8%A7%86%E9%A2%91%E4%B8%8B%E8%BD%BD":{"title":"Youtube 视频下载","content":"\n\n```cmd\n# 单独下载音频\nyt-dlp -f \"bestaudio[ext=m4a]\" 视频链接\n\n# 音频下载 m4a 转为 mp3 格式\nyt-dlp -f \"bestaudio[ext=m4a]\" --extract-audio --audio-format mp3 --audio-quality 0 视频链接\n\n# 视频下载最高质量\nyt-dlp \"bestvideo+bestaudio/best\" 视频链接\n\n# 选择视频和音频质量，会先展示不同种类的 id，然后根据 id 下载对应音视频文件就好\nyt-dlp -F 视频链接\n\n```\n\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/git-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98":{"title":"git","content":"### 远程仓库和本地仓库 commit 信息不一致\n经常会遇到远程仓库已经有提交记录来初始化仓库，然后因为一些原因一直在本地提交代码的情况出现，这样本地的提交记录和远程的提交记录完全不一样，可以说毫无关联。遇到这种情况应该：\n1. 首先添加远程仓库 `git remote add origin 远程仓库链接`\n2. fetch 远程仓库 `git fetch origin`\n3. 如果本地分支和远程分支名字不一样可以直接提交本地分支到远程分支上去\n4. 如果一样需要新建一个名字不一样的分支用来合并并且删除名字一样的分支\n\t1. `git checkout -D 需要删除分支的名字`\n\t2. `git checkout -b 名字不一样的分支`\n5. 然后切回远程分支的主分支上并在本地也创建一个相同的，然后本地合并之前的那个需要合并的分支，由于两个分支的提交信息完全不同所以需要使用一些参数\n\t1. `git merge 名字不一样的分支 --allow-unrelated-histories`\n\t2. 然后在本地解决掉有冲突的文件后再提交就合并了两个提交信息不一样的分支了\n\n### 回退 commit\n1. `git reset --soft HEAD^` 可以回退已经 commit 的代码，所有代码会再次回到暂存区\n\n### 连接 SSH\n1. 首先在自己电脑上生成公钥和私钥 `ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"`\n2. 添加 SSH 公钥到 SSH Agent\n\t1. 启动 SSH agent `eval \"$(ssh-agent -s)\"`\n\t2. 将 SSH 公钥添加到 SSH agent `ssh-add ~/.ssh/id_rsa`\n3. 将 SSH 公钥添加到 github 或者 gitee\n4. 克隆仓库或者将远程仓库地址由 https 变为 SSH `git remote set-url origin git@\u003cprovider\u003e:\u003cusername\u003e/\u003crepository\u003e.git`\n\n### 忽略已经提交的文件\n1. 将已经提交的文件忽略，在 gitignore 文件中添加需要忽略的文件\n2. 从 git 仓库中移除文件 `git rm --cached \u003cfile\u003e`\n3. 提交更改，远程仓库也对应删除这些需要忽略的文件\n","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/obsidian/Anuppuccin":{"title":"Anuppuccin","content":"\n\u003e [!NOTE] Anuppuccin\n\u003e 需要安装不少插件以及自定义\n\n## 插件","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/obsidian/Templater":{"title":"Templater","content":"待完善……","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null},"/python-%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83":{"title":"python 虚拟环境","content":"\n### 如何创建虚拟环境(win)\n1. `pip install virtualenvwrapper-win` 安装虚拟环境管理工具，统一设置虚拟环境存放位置\n\t2. `setx WORKON_HOME D:\\virtual_environments` 设置系统环境变量\n\t3. `mkvirtualenv myenv` 创建虚拟环境，此虚拟环境会存放在 D:\\virtual_environments 下，创建多个虚拟环境则会在文件夹下创建多个子文件夹\n2. `workon` 来列出所有的虚拟环境，`workon myenv` 则是进入创建的 myenv 环境，此时命令行前面会带此环境的标识\n3. 一般一个大项目对应一个虚拟环境，因为多个环境之间所需要的依赖也大不相同，版本之间也存在冲突\n4. 删除某个虚拟环境 `rmvirtualenv myenv`","lastmodified":"2023-05-08T06:15:26.262496913Z","tags":null}}